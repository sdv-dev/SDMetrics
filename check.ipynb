{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 5/5 [00:00<00:00, 2025.26it/s]\n",
      "  0%|          | 0/10.0 [00:00<?, ?it/s](2/2) Evaluating Column Pair Trends: :   0%|          | 0/10.0 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m report \u001b[39m=\u001b[39m QualityReport()\n\u001b[1;32m     15\u001b[0m \u001b[39m# Run\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m report\u001b[39m.\u001b[39;49mgenerate(real_data[column_names], synthetic_data[column_names], metadata)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Assert\u001b[39;00m\n\u001b[1;32m     19\u001b[0m expected_details_column_shapes_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mColumn\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mstart_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msecond_perc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwork_experience\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdegree_type\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     21\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMetric\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mKSComplement\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKSComplement\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTVComplement\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTVComplement\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     ],\n\u001b[1;32m     25\u001b[0m }\n",
      "File \u001b[0;32m~/Desktop/SDMetrics/sdmetrics/reports/base_report.py:95\u001b[0m, in \u001b[0;36mBaseReport.generate\u001b[0;34m(self, real_data, synthetic_data, metadata, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m     progress_bar \u001b[39m=\u001b[39m tqdm\u001b[39m.\u001b[39mtqdm(total\u001b[39m=\u001b[39mnum_iterations, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstdout)\n\u001b[1;32m     91\u001b[0m     progress_bar\u001b[39m.\u001b[39mset_description(\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mind\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_properties)\u001b[39m}\u001b[39;00m\u001b[39m) Evaluating \u001b[39m\u001b[39m{\u001b[39;00mproperty_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_properties[property_name]\u001b[39m.\u001b[39;49mget_score(\n\u001b[1;32m     96\u001b[0m     real_data, synthetic_data, metadata, progress_bar\u001b[39m=\u001b[39;49mprogress_bar\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     98\u001b[0m scores\u001b[39m.\u001b[39mappend(score)\n\u001b[1;32m     99\u001b[0m ind \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/SDMetrics/sdmetrics/reports/single_table/_properties/base.py:46\u001b[0m, in \u001b[0;36mBaseSingleTableProperty.get_score\u001b[0;34m(self, real_data, synthetic_data, metadata, progress_bar)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_score\u001b[39m(\u001b[39mself\u001b[39m, real_data, synthetic_data, metadata, progress_bar\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the average score for the property on the data.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m            The average score for the property.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_details(real_data, synthetic_data, metadata, progress_bar)\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_average()\n",
      "File \u001b[0;32m~/Desktop/SDMetrics/sdmetrics/reports/single_table/_properties/column_pair_trends.py:252\u001b[0m, in \u001b[0;36mColumnPairTrends._generate_details\u001b[0;34m(self, real_data, synthetic_data, metadata, progress_bar)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mprint\u001b[39m(progress_bar)\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_sdtypes:\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mif\u001b[39;00m progress_bar:\n\u001b[1;32m    253\u001b[0m         progress_bar\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m    255\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from sdmetrics.demos import load_demo\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "column_names = [\n",
    "    'student_id', 'degree_type', 'start_date', 'second_perc', 'work_experience'\n",
    "]\n",
    "real_data, synthetic_data, metadata = load_demo(modality='single_table')\n",
    "\n",
    "metadata['columns'] = {\n",
    "    key: val for key, val in metadata['columns'].items() if key in column_names\n",
    "}\n",
    "report = QualityReport()\n",
    "\n",
    "# Run\n",
    "report.generate(real_data[column_names], synthetic_data[column_names], metadata)\n",
    "\n",
    "# Assert\n",
    "expected_details_column_shapes_dict = {\n",
    "    'Column': ['start_date', 'second_perc', 'work_experience', 'degree_type'],\n",
    "    'Metric': ['KSComplement', 'KSComplement', 'TVComplement', 'TVComplement'],\n",
    "    'Score': [\n",
    "        0.7011066184294531, 0.627906976744186, 0.9720930232558139, 0.9255813953488372\n",
    "    ],\n",
    "}\n",
    "\n",
    "expected_details_cpt__dict = {\n",
    "    'Column 1': [\n",
    "        'start_date', 'start_date', 'start_date', 'second_perc',\n",
    "        'second_perc', 'work_experience'\n",
    "    ],\n",
    "    'Column 2': [\n",
    "        'second_perc', 'work_experience', 'degree_type', 'work_experience',\n",
    "        'degree_type', 'degree_type'\n",
    "    ],\n",
    "    'Metric': [\n",
    "        'CorrelationSimilarity', 'ContingencySimilarity', 'ContingencySimilarity',\n",
    "        'ContingencySimilarity', 'ContingencySimilarity', 'ContingencySimilarity'\n",
    "    ],\n",
    "    'Score': [\n",
    "        0.9854510263003199, 0.586046511627907, 0.6232558139534884, 0.7348837209302326,\n",
    "        0.6976744186046512, 0.8976744186046511\n",
    "    ],\n",
    "    'Real Correlation': [\n",
    "        0.04735340044317632, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    ],\n",
    "    'Synthetic Correlation': [\n",
    "        0.07645134784253645, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    ]\n",
    "}\n",
    "expected_details_column_shapes = pd.DataFrame(expected_details_column_shapes_dict)\n",
    "expected_details_cpt = pd.DataFrame(expected_details_cpt__dict)\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    report.get_details('Column Shapes'), expected_details_column_shapes\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    report.get_details('Column Pair Trends'), expected_details_cpt\n",
    ")\n",
    "assert report.get_score() == 0.7804181608907237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test the ``_get_cardinality`` method.\"\"\"\n",
    "import re\n",
    "from unittest.mock import Mock, call, patch\n",
    "\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from sdmetrics.visualization import (\n",
    "    _generate_cardinality_plot, _get_cardinality, get_cardinality_plot)\n",
    "from tests.utils import DataFrameMatcher, SeriesMatcher\n",
    "\n",
    "# Setup\n",
    "parent_table = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\n",
    "})\n",
    "child_table = pd.DataFrame({\n",
    "    'p_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'id': [1, 1, 2, 2, 2, 3, 3, 3, 3, 4]\n",
    "})\n",
    "parent_primary_key = 'id'\n",
    "child_foreign_key = 'id'\n",
    "\n",
    "# Run\n",
    "result = _get_cardinality(parent_table, child_table, parent_primary_key, child_foreign_key)\n",
    "\n",
    "# Assert\n",
    "expected_result = pd.Series(\n",
    "    [0, 1, 2, 3, 4], index=pd.Index([5, 4, 1, 2, 3], name='id'), name='# children'\n",
    ")\n",
    "\n",
    "pd.testing.assert_series_equal(result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sdmetrics.single_column import KeyUniqueness\n",
    "\n",
    "t0 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "t1 = pd.Series([1, 2, np.nan, 3, np.nan, 5, 2, np.nan, 6, None])\n",
    "\n",
    "KeyUniqueness.compute(t0, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A\n",
       "1      B\n",
       "2    NaN\n",
       "3      C\n",
       "4    NaN\n",
       "5      B\n",
       "6      A\n",
       "7    NaN\n",
       "8      D\n",
       "9      C\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A\n",
       "1      B\n",
       "2      C\n",
       "3      B\n",
       "4      A\n",
       "5    NaN\n",
       "6    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8    False\n",
       "9     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data = pd.Series(['A', 'B', np.nan, 'C', np.nan, 'B', 'A', None, 'D', 'C'])\n",
    "synthetic_data.duplicated() | synthetic_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example Series\n",
    "real_data = pd.Series(['A', 'B', 'C', 'B', 'A', None])\n",
    "#real_data = real_data.fillna(np.nan)\n",
    "synthetic_data = pd.Series(['A', 'B', np.nan, 'C', np.nan, 'B', 'A', None, 'D', 'C'])\n",
    "synthetic_data = synthetic_data.fillna(np.nan)\n",
    "\n",
    "# Compute the proportion\n",
    "proportion = synthetic_data.isin(real_data).mean()\n",
    "\n",
    "print(proportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.DataFrame({\n",
    "    'primary_key': [1, 2, 3, 4, 5],\n",
    "    'foreign_key': [1, 2, 3, 2, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "ignore_dtype_columns = None\n",
    "ignore_dtype_columns = ignore_dtype_columns or []\n",
    "if 'la' in ignore_dtype_columns:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'primary_key'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data['primary_key'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series2.isin(series1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "5    0\n",
       "4    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "Name: # children, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "issue-394-multi-table-diagnostic-reports",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
